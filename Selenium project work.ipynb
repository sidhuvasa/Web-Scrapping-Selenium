{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9f50c4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\user\\anaconda3\\lib\\site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from selenium) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "# importing the necessary libraries\n",
    "!pip install selenium\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "74faca05",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options=Options()\n",
    "chrome_options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "driver= webdriver.Chrome( r\"C:\\Users\\user\\Downloads\\chromedriver_win32\\chromedriver.exe\",options=chrome_options)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcc2177",
   "metadata": {},
   "source": [
    "Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "08aacbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the naukri portal url on the web driver\n",
    "url = \"https://www.naukri.com/\"\n",
    "\n",
    "driver.maximize_window()\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "# code to write Data Analyst on search box\n",
    "search_job = driver.find_element_by_xpath('//input[@class=\"sugInp\"]')\n",
    "search_job.send_keys(\"Data Analyst\")\n",
    "\n",
    "# code to write Bangalore in location box\n",
    "search_loc = driver.find_element_by_xpath('//input[@name=\"location\"]')\n",
    "search_loc.send_keys(\"Bangalore\")\n",
    "\n",
    "# code to click on the search button\n",
    "search_btn = driver.find_element_by_xpath('//button[@class=\"btn\"]')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "679995bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths of columns: 10 10 10 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company Names</th>\n",
       "      <th>Years of experience required</th>\n",
       "      <th>Job Locations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Gaussian Networks Private Limited</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tcs Hiring For Senior Data Analyst (bfsi domain)</td>\n",
       "      <td>Tata Consultancy Services Ltd.</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "      <td>Chennai, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>Trigent Software</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>Trigent Software</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Business Data Analyst - Google Data Studio &amp; SQL</td>\n",
       "      <td>AVE-Promagne</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Virtusa Consulting Services Pvt Ltd</td>\n",
       "      <td>8-12 Yrs</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tcs Hiring For MDM (master data management) Da...</td>\n",
       "      <td>Tata Consultancy Services Ltd.</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "      <td>(WFH during Covid)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Analyst IDAM Services</td>\n",
       "      <td>GlaxoSmithKline Pharmaceuticals Limited</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "      <td>Chennai, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst/Sr.Data Engineer</td>\n",
       "      <td>SYREN TECHNOLOGIES PRIVATE LIMITED</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SENIOR DATA ANALYST</td>\n",
       "      <td>McAfee Software (India) Pvt. Ltd</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "      <td>Hyderabad/Secunderabad, Chennai, Bangalore/Ben...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0                                Senior Data Analyst   \n",
       "1   Tcs Hiring For Senior Data Analyst (bfsi domain)   \n",
       "2                              Business Data Analyst   \n",
       "3                              Business Data Analyst   \n",
       "4   Business Data Analyst - Google Data Studio & SQL   \n",
       "5                                Senior Data Analyst   \n",
       "6  Tcs Hiring For MDM (master data management) Da...   \n",
       "7                  Senior Data Analyst IDAM Services   \n",
       "8                      Data Analyst/Sr.Data Engineer   \n",
       "9                                SENIOR DATA ANALYST   \n",
       "\n",
       "                             Company Names Years of experience required  \\\n",
       "0        Gaussian Networks Private Limited                      3-5 Yrs   \n",
       "1           Tata Consultancy Services Ltd.                     6-11 Yrs   \n",
       "2                         Trigent Software                     5-10 Yrs   \n",
       "3                         Trigent Software                     5-10 Yrs   \n",
       "4                             AVE-Promagne                      3-8 Yrs   \n",
       "5      Virtusa Consulting Services Pvt Ltd                     8-12 Yrs   \n",
       "6           Tata Consultancy Services Ltd.                     6-11 Yrs   \n",
       "7  GlaxoSmithKline Pharmaceuticals Limited                      4-8 Yrs   \n",
       "8       SYREN TECHNOLOGIES PRIVATE LIMITED                      4-9 Yrs   \n",
       "9         McAfee Software (India) Pvt. Ltd                      6-8 Yrs   \n",
       "\n",
       "                                       Job Locations  \n",
       "0              Gurgaon/Gurugram, Bangalore/Bengaluru  \n",
       "1                       Chennai, Bangalore/Bengaluru  \n",
       "2                                Bangalore/Bengaluru  \n",
       "3                                Bangalore/Bengaluru  \n",
       "4                                Bangalore/Bengaluru  \n",
       "5  Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram...  \n",
       "6                                 (WFH during Covid)  \n",
       "7                       Chennai, Bangalore/Bengaluru  \n",
       "8                                Bangalore/Bengaluru  \n",
       "9  Hyderabad/Secunderabad, Chennai, Bangalore/Ben...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract all the job titles\n",
    "job_titles = driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "titles = []\n",
    "for i in job_titles[:10]:\n",
    "    titles.append(i.text)\n",
    "\n",
    "# extract all the company names\n",
    "job_companies = driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "companies = []\n",
    "for i in job_companies[:10]:\n",
    "    companies.append(i.text)\n",
    "\n",
    "# extract the years of experience needed\n",
    "job_exp = driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "exp = []\n",
    "for i in job_exp[:10]:\n",
    "    exp.append(i.text)\n",
    "\n",
    "# extract all the job locations including Bangalore and the others with it\n",
    "job_locations = driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]//span')\n",
    "location = []\n",
    "for i in job_locations[:10]:\n",
    "    location.append(i.text)\n",
    "\n",
    "# checking the length to get data frame\n",
    "print(\"Lengths of columns:\", len(titles), len(companies), len(exp), len(location))\n",
    "\n",
    "# creating the dataframe now\n",
    "df = pd.DataFrame({})\n",
    "df['Job Title']=titles\n",
    "df['Company Names']=companies\n",
    "df['Years of experience required']=exp\n",
    "df['Job Locations']=location\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7776eecf",
   "metadata": {},
   "source": [
    "Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4d77dcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the naukri portal url on the web driver\n",
    "url = \"https://www.naukri.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "# code to write Data Scientist on search box\n",
    "search_job = driver.find_element_by_xpath('//input[@class=\"sugInp\"]')\n",
    "search_job.send_keys(\"Data Scientist\")\n",
    "\n",
    "# code to write Bangalore in location box\n",
    "search_loc = driver.find_element_by_xpath('//input[@name=\"location\"]')\n",
    "search_loc.send_keys(\"Bangalore\")\n",
    "\n",
    "# code to click on the search button\n",
    "search_btn = driver.find_element_by_xpath('//button[@class=\"btn\"]')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6ecaf31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "\n",
    "# extract all the job search links from the above search result\n",
    "job_urls=[]\n",
    "for i in url:\n",
    "    job_urls.append(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "471d2099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths of columns: 15 15 15 15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company Names</th>\n",
       "      <th>Job Locations</th>\n",
       "      <th>Job Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hiring For Data Scientist</td>\n",
       "      <td>Tata Consultancy Services Ltd.</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Job description Minumum 3 years of experience ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Job description Use predictive modeling to inc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Walmart Labs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Job description As a Senior Data Scientist for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Airbnb</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Job description Responsibilities include: Defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SENIOR DATA SCIENTIST</td>\n",
       "      <td>Happiest Minds Technologies Pvt.Ltd</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Job description   Skills Required Skills: Data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Scientist IN4</td>\n",
       "      <td>Walmart Labs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Job description Design, coordinate, and implem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Scientist (Marketplace)</td>\n",
       "      <td>Walmart Labs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Job description Position Responsibilities o So...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hiring For Manager and Sr. Manager | Data Scie...</td>\n",
       "      <td>Vision Beyond Resources India Private Limited</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Job description Hello, We are hiring on behalf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Requirement For Data Scientist - Mumbai &amp; Bang...</td>\n",
       "      <td>CRISIL LIMITED</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Job description  CRISIL (formerly Credit Ratin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist (Python &amp; SQL)</td>\n",
       "      <td>AVE-Promagne</td>\n",
       "      <td>Hyderabad/Secunderabad</td>\n",
       "      <td>Job description Required Technical and Profess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Lead Data Scientist - Machine Learning/ Data M...</td>\n",
       "      <td>Wrackle Technologies Pvt Ltd</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Job description Roles and Responsibilities Req...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Data Scientist- Senior Business Analyst/Lead A...</td>\n",
       "      <td>Evalueserve.com Pvt. Ltd</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Job description Job Description Understand and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Data Scientist - IN3</td>\n",
       "      <td>Walmart Labs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Job description Your Responsibility Develop th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Principal Data Scientist (MINT)</td>\n",
       "      <td>Walmart Labs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Job description Your Opportunity To fulfill th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Freelance Data Scientist Project Based</td>\n",
       "      <td>Shikvix</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Job description  Job description:  Seeking sen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Job Title  \\\n",
       "0                           Hiring For Data Scientist   \n",
       "1                            Associate Data Scientist   \n",
       "2                               Senior Data Scientist   \n",
       "3                               Senior Data Scientist   \n",
       "4                               SENIOR DATA SCIENTIST   \n",
       "5                           Senior Data Scientist IN4   \n",
       "6                 Senior Data Scientist (Marketplace)   \n",
       "7   Hiring For Manager and Sr. Manager | Data Scie...   \n",
       "8   Requirement For Data Scientist - Mumbai & Bang...   \n",
       "9                       Data Scientist (Python & SQL)   \n",
       "10  Lead Data Scientist - Machine Learning/ Data M...   \n",
       "11  Data Scientist- Senior Business Analyst/Lead A...   \n",
       "12                               Data Scientist - IN3   \n",
       "13                    Principal Data Scientist (MINT)   \n",
       "14             Freelance Data Scientist Project Based   \n",
       "\n",
       "                                    Company Names           Job Locations  \\\n",
       "0                  Tata Consultancy Services Ltd.                 Chennai   \n",
       "1                           Philips India Limited     Bangalore/Bengaluru   \n",
       "2                                    Walmart Labs     Bangalore/Bengaluru   \n",
       "3                                          Airbnb     Bangalore/Bengaluru   \n",
       "4             Happiest Minds Technologies Pvt.Ltd     Bangalore/Bengaluru   \n",
       "5                                    Walmart Labs     Bangalore/Bengaluru   \n",
       "6                                    Walmart Labs     Bangalore/Bengaluru   \n",
       "7   Vision Beyond Resources India Private Limited                   Noida   \n",
       "8                                  CRISIL LIMITED     Bangalore/Bengaluru   \n",
       "9                                    AVE-Promagne  Hyderabad/Secunderabad   \n",
       "10                   Wrackle Technologies Pvt Ltd     Bangalore/Bengaluru   \n",
       "11                       Evalueserve.com Pvt. Ltd        Gurgaon/Gurugram   \n",
       "12                                   Walmart Labs     Bangalore/Bengaluru   \n",
       "13                                   Walmart Labs     Bangalore/Bengaluru   \n",
       "14                                        Shikvix     Bangalore/Bengaluru   \n",
       "\n",
       "                                      Job Description  \n",
       "0   Job description Minumum 3 years of experience ...  \n",
       "1   Job description Use predictive modeling to inc...  \n",
       "2   Job description As a Senior Data Scientist for...  \n",
       "3   Job description Responsibilities include: Defi...  \n",
       "4   Job description   Skills Required Skills: Data...  \n",
       "5   Job description Design, coordinate, and implem...  \n",
       "6   Job description Position Responsibilities o So...  \n",
       "7   Job description Hello, We are hiring on behalf...  \n",
       "8   Job description  CRISIL (formerly Credit Ratin...  \n",
       "9   Job description Required Technical and Profess...  \n",
       "10  Job description Roles and Responsibilities Req...  \n",
       "11  Job description Job Description Understand and...  \n",
       "12  Job description Your Responsibility Develop th...  \n",
       "13  Job description Your Opportunity To fulfill th...  \n",
       "14  Job description  Job description:  Seeking sen...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract all the job titles\n",
    "titles = []\n",
    "for i in job_urls:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        job_titles = driver.find_element_by_xpath('//h1[@class=\"jd-header-title\"]')\n",
    "        titles.append(job_titles.text)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# extract all the company names\n",
    "companies = []\n",
    "for i in job_urls:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        job_companies = driver.find_element_by_xpath('//a[@class=\"pad-rt-8\"]')\n",
    "        companies.append(job_companies.text)\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "# extract all the job locations including Bangalore and the others with it\n",
    "location = []\n",
    "for i in job_urls:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        job_locations = driver.find_element_by_xpath('//span[@class=\"location \"]//a')\n",
    "        location.append(job_locations.text)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "# extract the complete job description\n",
    "description = []\n",
    "for i in job_urls:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        job_description = driver.find_element_by_xpath('//section[@class=\"job-desc\"]')\n",
    "        description.append(job_description.text.replace(\"\\n\",\" \"))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# checking the length for creating data frame\n",
    "print(\"Lengths of columns:\", len(titles), len(companies), len(location), len(description))\n",
    "\n",
    "# creating the data frame now\n",
    "df = pd.DataFrame({})\n",
    "df['Job Title']=titles\n",
    "df['Company Names']=companies\n",
    "df['Job Locations']=location\n",
    "df['Job Description']=description\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44c9340",
   "metadata": {},
   "source": [
    "Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bb810948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the naukri portal url on the web driver\n",
    "url = \"https://www.naukri.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "# code to write Data Scientist on search box\n",
    "search_job = driver.find_element_by_xpath('//input[@class=\"sugInp\"]')\n",
    "search_job.send_keys(\"Data Scientist\")\n",
    "\n",
    "# code to click on the search button\n",
    "search_btn = driver.find_element_by_xpath('//button[@class=\"btn\"]')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1adaeb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to click on the location filter for \"Delhi/NCR\"\n",
    "location_filter = driver.find_element_by_xpath('/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[3]/div[2]/div[3]/label/i')\n",
    "location_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5f02a67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to click on the salary filter for \"3-6 Lakhs\"\n",
    "salary_filter = driver.find_element_by_xpath('/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[4]/div[2]/div[2]/label/i')\n",
    "salary_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ef15db14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths of columns: 10 10 10 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company Names</th>\n",
       "      <th>Years of experience required</th>\n",
       "      <th>Job Locations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist/ Machine Learning Engineer</td>\n",
       "      <td>Creative Hands HR Consultancy</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Ahmedabad, Gurga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist / Data Analyst / Business Analy...</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "      <td>Ghaziabad, Faridabad, Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist / Data Analyst</td>\n",
       "      <td>CARS24</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Only Fresher / Data Scientist / Data Analyst /...</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist / Data Analyst / Business Analy...</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "      <td>Noida, New Delhi, Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>R Systems International Ltd.</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>PROCESS NINE TECHNOLOGIES PVT.LTD.</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>(WFH during Covid)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - Insurance</td>\n",
       "      <td>Huquo Consulting Pvt. Ltd</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist - WFH - MIND Infotech</td>\n",
       "      <td>MOTHERSONSUMI INFOTECH &amp; DESIGNS LIMITED</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>(WFH during Covid)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Junior Data Scientists &amp; Engineers</td>\n",
       "      <td>PY Consultancy</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>Noida, Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0          Data Scientist/ Machine Learning Engineer   \n",
       "1  Data Scientist / Data Analyst / Business Analy...   \n",
       "2                      Data Scientist / Data Analyst   \n",
       "3  Only Fresher / Data Scientist / Data Analyst /...   \n",
       "4  Data Scientist / Data Analyst / Business Analy...   \n",
       "5                                     Data Scientist   \n",
       "6                                     Data Scientist   \n",
       "7                         Data Scientist - Insurance   \n",
       "8               Data Scientist - WFH - MIND Infotech   \n",
       "9                 Junior Data Scientists & Engineers   \n",
       "\n",
       "                              Company Names Years of experience required  \\\n",
       "0             Creative Hands HR Consultancy                      0-0 Yrs   \n",
       "1                 GABA Consultancy services                      0-0 Yrs   \n",
       "2                                    CARS24                      1-5 Yrs   \n",
       "3                 GABA Consultancy services                      0-0 Yrs   \n",
       "4                 GABA Consultancy services                      0-0 Yrs   \n",
       "5              R Systems International Ltd.                      3-6 Yrs   \n",
       "6        PROCESS NINE TECHNOLOGIES PVT.LTD.                      1-3 Yrs   \n",
       "7                 Huquo Consulting Pvt. Ltd                      2-7 Yrs   \n",
       "8  MOTHERSONSUMI INFOTECH & DESIGNS LIMITED                      3-7 Yrs   \n",
       "9                            PY Consultancy                      0-3 Yrs   \n",
       "\n",
       "                                       Job Locations  \n",
       "0  Hyderabad/Secunderabad, Pune, Ahmedabad, Gurga...  \n",
       "1                  Ghaziabad, Faridabad, Delhi / NCR  \n",
       "2                                   Gurgaon/Gurugram  \n",
       "3               Noida, Gurgaon/Gurugram, Delhi / NCR  \n",
       "4                 Noida, New Delhi, Gurgaon/Gurugram  \n",
       "5                                              Noida  \n",
       "6                                 (WFH during Covid)  \n",
       "7                                   Gurgaon/Gurugram  \n",
       "8                                 (WFH during Covid)  \n",
       "9                            Noida, Gurgaon/Gurugram  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract all the job titles\n",
    "j_title = driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "f_title = []\n",
    "for i in j_title[:10]:\n",
    "    f_title.append(i.text)\n",
    "\n",
    "# extract all the company names\n",
    "j_company = driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "f_company = []\n",
    "for i in j_company[:10]:\n",
    "    f_company.append(i.text)\n",
    "\n",
    "# extract the years of experience needed\n",
    "j_exp = driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "f_exp = []\n",
    "for i in j_exp[:10]:\n",
    "    f_exp.append(i.text)\n",
    "\n",
    "# extract all the job locations including Bangalore and the others with it\n",
    "j_location = driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]//span')\n",
    "f_location = []\n",
    "for i in j_location[:10]:\n",
    "    f_location.append(i.text)\n",
    "\n",
    "# checking the length for getting the data frame\n",
    "print(\"Lengths of columns:\", len(f_title), len(f_company), len(f_exp), len(f_location))\n",
    "\n",
    "# creating the data frame now\n",
    "df = pd.DataFrame({})\n",
    "df['Job Title']=f_title\n",
    "df['Company Names']=f_company\n",
    "df['Years of experience required']=f_exp\n",
    "df['Job Locations']=f_location\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6697780",
   "metadata": {},
   "source": [
    "Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c43bcd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the glassdoor job search portal url on the web driver\n",
    "url = \"https://www.glassdoor.co.in/member/home/index.htm\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5d0ca0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the element for Job Search using xpath\n",
    "search_job = driver.find_element_by_xpath(\"//input[@id='sc.keyword']\")\n",
    "\n",
    "# Writing the required input in the search bar\n",
    "search_job.send_keys(\"Data Scientist\")\n",
    "\n",
    "# Finding the element for Job Location using xpath\n",
    "job_location = driver.find_element_by_xpath(\"//input[@id='sc.location']\")\n",
    "\n",
    "# Writing the required input in the search bar\n",
    "job_location.send_keys(\"Noida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0451d1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the element for Company Name using xpath\n",
    "company_name = driver.find_elements_by_xpath(\"//div[@class='d-flex justify-content-between align-items-start']//a\")\n",
    "\n",
    "# We will run a loop to iterate all the Company Name tags extracted above and extract the text inside them\n",
    "Company_Name = []\n",
    "for i in company_name:\n",
    "    Company_Name.append(i.text)\n",
    "    \n",
    "# Finding the element for Job Posted using xpath\n",
    "job_posted = driver.find_elements_by_xpath(\"//div[@class='d-flex align-items-end pl-std css-17n8uzw']\")\n",
    "\n",
    "# We will run a loop to iterate all the Job Posted tags extracted above and extract the text inside them\n",
    "Job_Posted = []\n",
    "for i in job_posted:\n",
    "    Job_Posted.append(i.text)\n",
    "\n",
    "# Finding the element for different Job url using xpath\n",
    "rating_url = driver.find_elements_by_xpath(\"//a[@class='job-search-key-l2wjgv e1n63ojh0 jobLink']\")\n",
    "\n",
    "# We will run a loop to iterate all the url links extracted above and extract the href inside them\n",
    "Rating_Url = []\n",
    "for i in rating_url:\n",
    "    Rating_Url.append(i.get_attribute(\"href\"))\n",
    "\n",
    "Ratings = []\n",
    "for i in Rating_Url:\n",
    "    driver.get(i)\n",
    "    # Extracting Rating using xpath\n",
    "    try:\n",
    "        ratings = driver.find_element_by_xpath(\"//span[@class='css-1pmc6te e11nt52q4']\")\n",
    "        # We will run a loop to iterate all the ratings tags extracted above and extract the text inside them\n",
    "        Ratings.append(ratings.text.replace(\"\\n\",\" \"))\n",
    "    except:\n",
    "        Ratings.append(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893eba28",
   "metadata": {},
   "outputs": [],
   "source": [
    " # creating the dataframe from the scraped data and taking only first 10 jobs\n",
    "Job = pd.DataFrame({\"Company_Name\":company_name[0:10],\"Job_Posted\":job_posted[0:10],\"Rating_url\":rating_url[0:10]})\n",
    "Job.reset_index(drop=True,inplace = True)\n",
    "Job.index+= 1\n",
    "Job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba647e6",
   "metadata": {},
   "source": [
    "Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0ed72386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the glassdoor job search portal url on the web driver\n",
    "url = \"https://www.glassdoor.co.in/Salaries/index.htm\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b4a2c86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to write Data Scientist on skills search box\n",
    "search_job = driver.find_element_by_xpath('//input[@id=\"KeywordSearch\"]')\n",
    "search_job.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e112b006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to write Noida in location box\n",
    "search_loc = driver.find_element_by_xpath('//input[@id=\"LocationSearch\"]')\n",
    "search_loc.send_keys(\"Noida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "844b0739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to click on the search button\n",
    "search_btn = driver.find_element_by_xpath('//button[@id=\"HeroSearchButton\"]')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9cc2caa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the element for different Job url using xpath\n",
    "rating_url = driver.find_elements_by_xpath(\"//a[@class='job-search-key-l2wjgv e1n63ojh0 jobLink']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f225276a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths of columns: 10 10 10 10 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Minimum Salary</th>\n",
       "      <th>Maximum Salary</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Average Salary</th>\n",
       "      <th>Company Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>₹4L</td>\n",
       "      <td>₹13L</td>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>₹6,28,021</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>₹1L</td>\n",
       "      <td>₹28L</td>\n",
       "      <td>IBM</td>\n",
       "      <td>₹9,08,246</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>₹6L</td>\n",
       "      <td>₹23L</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>₹11,93,390</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>₹5L</td>\n",
       "      <td>₹1Cr</td>\n",
       "      <td>Delhivery</td>\n",
       "      <td>₹12,49,716</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>₹4L</td>\n",
       "      <td>₹17L</td>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>₹7,58,335</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>₹8L</td>\n",
       "      <td>₹16L</td>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>₹12,80,000</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>₹8L</td>\n",
       "      <td>₹20L</td>\n",
       "      <td>Optum</td>\n",
       "      <td>₹12,70,000</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>₹10L</td>\n",
       "      <td>₹18L</td>\n",
       "      <td>Optum Global Solutions</td>\n",
       "      <td>₹14,55,430</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>₹5L</td>\n",
       "      <td>₹15L</td>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>₹8,86,064</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>₹6L</td>\n",
       "      <td>₹16L</td>\n",
       "      <td>EXL Service</td>\n",
       "      <td>₹11,10,000</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Minimum Salary Maximum Salary               Company Name Average Salary  \\\n",
       "0            ₹4L           ₹13L  Tata Consultancy Services      ₹6,28,021   \n",
       "1            ₹1L           ₹28L                        IBM      ₹9,08,246   \n",
       "2            ₹6L           ₹23L                  Accenture     ₹11,93,390   \n",
       "3            ₹5L           ₹1Cr                  Delhivery     ₹12,49,716   \n",
       "4            ₹4L           ₹17L         Ericsson-Worldwide      ₹7,58,335   \n",
       "5            ₹8L           ₹16L         UnitedHealth Group     ₹12,80,000   \n",
       "6            ₹8L           ₹20L                      Optum     ₹12,70,000   \n",
       "7           ₹10L           ₹18L     Optum Global Solutions     ₹14,55,430   \n",
       "8            ₹5L           ₹15L         Valiance Solutions      ₹8,86,064   \n",
       "9            ₹6L           ₹16L                EXL Service     ₹11,10,000   \n",
       "\n",
       "  Company Rating  \n",
       "0            3.9  \n",
       "1            3.9  \n",
       "2            4.1  \n",
       "3            3.7  \n",
       "4              4  \n",
       "5            3.7  \n",
       "6            3.7  \n",
       "7            3.9  \n",
       "8            4.2  \n",
       "9            3.6  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code to get the minimum salary\n",
    "min_sal = driver.find_elements_by_xpath('//div[@class=\"d-flex mt-xxsm css-79elbk epuxyqn0\"]//p')\n",
    "minsal=[]\n",
    "for i in min_sal[:20]:\n",
    "    minsal.append(i.text)\n",
    "minisal=[]\n",
    "for i in range(0, len(minsal), 2):\n",
    "    minisal.append(minsal[i])\n",
    "\n",
    "# code to get the maximum salary\n",
    "maxisal=[]\n",
    "for i in range(1, len(minsal), 2):\n",
    "    maxisal.append(minsal[i])\n",
    "    \n",
    "# code to get the company names\n",
    "com_name = driver.find_elements_by_xpath('//a[@class=\"css-f3vw95 e1aj7ssy3\"]')\n",
    "cname = []\n",
    "for i in com_name[:10]:\n",
    "    cname.append(i.text)\n",
    "\n",
    "# code to get the average salary\n",
    "avg_sal = driver.find_elements_by_xpath('//div[@class=\"col-12 col-lg-4 px-lg-0 d-flex align-items-baseline\"]//h3')\n",
    "avgsal = []\n",
    "for i in avg_sal[:10]:\n",
    "    avgsal.append(i.text)\n",
    "    \n",
    "# code to get the rating of the company\n",
    "com_rating = driver.find_elements_by_xpath('//span[@class=\"m-0 css-kyx745\"]')\n",
    "crating = []\n",
    "for i in com_rating[:10]:\n",
    "    crating.append(i.text)\n",
    "    \n",
    "# checking the length to get the data frame\n",
    "print(\"Lengths of columns:\", len(minisal), len(maxisal), len(cname), len(avgsal), len(crating))\n",
    "\n",
    "# creating the data frame now\n",
    "df = pd.DataFrame({})\n",
    "df['Minimum Salary']=minisal\n",
    "df['Maximum Salary']=maxisal\n",
    "df['Company Name']=cname\n",
    "df['Average Salary']=avgsal\n",
    "df['Company Rating']=crating\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57721e5",
   "metadata": {},
   "source": [
    "Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d567055a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.flipkart.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa82564b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to write sunglasses in the search box\n",
    "search_prod = driver.find_element_by_xpath('//input[@class=\"_3704LK\"]')\n",
    "search_prod.send_keys(\"Sunglasses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb429f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to click on the search button\n",
    "search_btn = driver.find_element_by_xpath('//button[@class=\"L0Z3Pu\"]')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7357a138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to extract brand details\n",
    "prod_brand = driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "brand = []\n",
    "for i in prod_brand:\n",
    "    brand.append(i.text)\n",
    "\n",
    "# code to extract product description\n",
    "prod_descriptn = driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "descriptn = []\n",
    "for i in prod_descriptn:\n",
    "    try:\n",
    "        descriptn.append(i.text)\n",
    "    except:\n",
    "        descriptn.appendend(\"No description available\")\n",
    "\n",
    "# code to extract price of the product\n",
    "prod_price = driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "price = []\n",
    "for i in prod_price:\n",
    "    price.append(i.text)\n",
    "\n",
    "# code to extract the discount percentage\n",
    "prod_discount = driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]//span')\n",
    "discount = []\n",
    "for i in prod_discount:\n",
    "    discount.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55dc3d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to click on the next button for page 2\n",
    "search_btn1 = driver.find_element_by_xpath('/html/body/div/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]')\n",
    "search_btn1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5919d677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to extract brand details\n",
    "prod_brand = driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "for i in prod_brand:\n",
    "    brand.append(i.text)\n",
    "\n",
    "# code to extract product description\n",
    "prod_descriptn = driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "for i in prod_descriptn:\n",
    "    try:\n",
    "        descriptn.append(i.text)\n",
    "    except:\n",
    "        descriptn.appendend(\"No description available\")\n",
    "\n",
    "# code to extract price of the product\n",
    "prod_price = driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "for i in prod_price:\n",
    "    price.append(i.text)\n",
    "\n",
    "# code to extract the discount percentage\n",
    "prod_discount = driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]//span')\n",
    "for i in prod_discount:\n",
    "    discount.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1654aed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to click on the next button for page 3\n",
    "search_btn2 = driver.find_element_by_xpath('/html/body/div/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[12]')\n",
    "search_btn2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a2c5c9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths of columns: 120 117 120 120\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sunglasses Brand</th>\n",
       "      <th>Sunglasses Description</th>\n",
       "      <th>Sunglasses Price</th>\n",
       "      <th>Sunglasses Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (Free Size)</td>\n",
       "      <td>₹331</td>\n",
       "      <td>79% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (32)</td>\n",
       "      <td>₹237</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "      <td>₹295</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SHAAH COLLECTIONS</td>\n",
       "      <td>UV Protection, Polarized, Mirrored Rectangular...</td>\n",
       "      <td>₹198</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kingsunglasses</td>\n",
       "      <td>Mirrored, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹284</td>\n",
       "      <td>89% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>UV Protection Aviator Sunglasses (58)</td>\n",
       "      <td>₹403</td>\n",
       "      <td>72% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Polarized Aviator Sunglasses (60)</td>\n",
       "      <td>₹449</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection Round Sunglasses (50)</td>\n",
       "      <td>₹449</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>UV Protection Aviator Sunglasses (Free Size)</td>\n",
       "      <td>₹202</td>\n",
       "      <td>74% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection, Polarized Aviator Sunglasses (32)</td>\n",
       "      <td>₹711</td>\n",
       "      <td>64% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sunglasses Brand                             Sunglasses Description  \\\n",
       "0              PIRASO       UV Protection Aviator Sunglasses (Free Size)   \n",
       "1              PIRASO             UV Protection Wayfarer Sunglasses (32)   \n",
       "2           Elligator                UV Protection Round Sunglasses (54)   \n",
       "3   SHAAH COLLECTIONS  UV Protection, Polarized, Mirrored Rectangular...   \n",
       "4      kingsunglasses  Mirrored, UV Protection Wayfarer Sunglasses (F...   \n",
       "..                ...                                                ...   \n",
       "95              NuVew              UV Protection Aviator Sunglasses (58)   \n",
       "96     ROZZETTA CRAFT   UV Protection, Polarized Aviator Sunglasses (60)   \n",
       "97     ROZZETTA CRAFT                UV Protection Round Sunglasses (50)   \n",
       "98              NuVew       UV Protection Aviator Sunglasses (Free Size)   \n",
       "99          ROYAL SON   UV Protection, Polarized Aviator Sunglasses (32)   \n",
       "\n",
       "   Sunglasses Price Sunglasses Discount  \n",
       "0              ₹331             79% off  \n",
       "1              ₹237             85% off  \n",
       "2              ₹295             88% off  \n",
       "3              ₹198             88% off  \n",
       "4              ₹284             89% off  \n",
       "..              ...                 ...  \n",
       "95             ₹403             72% off  \n",
       "96             ₹449             77% off  \n",
       "97             ₹449             77% off  \n",
       "98             ₹202             74% off  \n",
       "99             ₹711             64% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code to extract brand details\n",
    "prod_brand = driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "for i in prod_brand:\n",
    "    brand.append(i.text)\n",
    "\n",
    "# code to extract product description\n",
    "prod_descriptn = driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "for i in prod_descriptn:\n",
    "    try:\n",
    "        descriptn.append(i.text)\n",
    "    except:\n",
    "        descriptn.append(\"No description available\")\n",
    "\n",
    "# code to extract price of the product\n",
    "prod_price = driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "for i in prod_price:\n",
    "    price.append(i.text)\n",
    "\n",
    "# code to extract the discount percentage\n",
    "prod_discount = driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]//span')\n",
    "for i in prod_discount:\n",
    "    discount.append(i.text)\n",
    "    \n",
    "# checking the length to get the data frame\n",
    "print(\"Lengths of columns:\", len(brand), len(descriptn), len(price), len(discount))\n",
    "\n",
    "# creating the data frame now\n",
    "df = pd.DataFrame({})\n",
    "df['Sunglasses Brand']=brand[:100]\n",
    "df['Sunglasses Description']=descriptn[:100]\n",
    "df['Sunglasses Price']=price[:100]\n",
    "df['Sunglasses Discount']=discount[:100]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54945fe8",
   "metadata": {},
   "source": [
    "Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "67ac5657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the flipkart shopping site url on the web driver\n",
    "url = \"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e75c20fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = driver.find_elements_by_xpath('//nav[@class=\"yFHi8N\"]//a')\n",
    "\n",
    "# extract all the job search links from the above search result\n",
    "prod_urls=[]\n",
    "for i in url[:11]:\n",
    "    prod_urls.append(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f05067c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths of columns: 108 110 110\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iPhone Rating</th>\n",
       "      <th>iPhone Short Summary</th>\n",
       "      <th>iPhone Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money  The iPhone 11 of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Just wow!</td>\n",
       "      <td>The ultimate performance Camera is superb The ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>3</td>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>I use a Note10+ and have been using both iOS a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>The phone is completely good As far as camera ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Decent product</td>\n",
       "      <td>Everything u ll like it when u use this iPhone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>Can’t beat the software and hardware integrati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   iPhone Rating iPhone Short Summary  \\\n",
       "0              5            Brilliant   \n",
       "1              5       Simply awesome   \n",
       "2              5  Best in the market!   \n",
       "3              5     Perfect product!   \n",
       "4              5            Fabulous!   \n",
       "..           ...                  ...   \n",
       "95             5            Just wow!   \n",
       "96             3    Terrific purchase   \n",
       "97             5              Awesome   \n",
       "98             5       Decent product   \n",
       "99             5              Awesome   \n",
       "\n",
       "                                   iPhone Full Review  \n",
       "0   The Best Phone for the Money  The iPhone 11 of...  \n",
       "1   Really satisfied with the Product I received.....  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3   Amazing phone with great cameras and better ba...  \n",
       "4   This is my first iOS phone. I am very happy wi...  \n",
       "..                                                ...  \n",
       "95  The ultimate performance Camera is superb The ...  \n",
       "96  I use a Note10+ and have been using both iOS a...  \n",
       "97  The phone is completely good As far as camera ...  \n",
       "98  Everything u ll like it when u use this iPhone...  \n",
       "99  Can’t beat the software and hardware integrati...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract all the ratings for the iPhone\n",
    "phone_rating = []\n",
    "for i in prod_urls:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        prod_rating = driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "        for j in prod_rating:\n",
    "            phone_rating.append(j.text)\n",
    "    except:\n",
    "        phone_rating.append(\"---\")\n",
    "\n",
    "# extract all the review summary for the iPhone\n",
    "phone_summary = []\n",
    "for i in prod_urls:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        prod_summaries = driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "        for j in prod_summaries:\n",
    "            phone_summary.append(j.text)\n",
    "    except:\n",
    "        phone_summary.append(\"---\")\n",
    "\n",
    "# extract all the complete descriptive review for the iPhone\n",
    "full_review = []\n",
    "for i in prod_urls:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        prod_reviews = driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "        for j in prod_reviews:\n",
    "            full_review.append(j.text.replace(\"\\n\",\" \"))\n",
    "    except:\n",
    "        full_review.append(\"---\")\n",
    "\n",
    "# checking the length to get the data frame\n",
    "print(\"Lengths of columns:\", len(phone_rating), len(phone_summary), len(full_review))\n",
    "\n",
    "# creating the data frame now\n",
    "df = pd.DataFrame({})\n",
    "df['iPhone Rating']=phone_rating[:100]\n",
    "df['iPhone Short Summary']=phone_summary[:100]\n",
    "df['iPhone Full Review']=full_review[:100]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75b98d7",
   "metadata": {},
   "source": [
    "Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3a468ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the flipkart shopping site url on the web driver\n",
    "url = \"https://www.flipkart.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "# code to write sneakers in the search box\n",
    "search_prod = driver.find_element_by_xpath('//input[@class=\"_3704LK\"]')\n",
    "search_prod.send_keys(\"Sneakers\")\n",
    "\n",
    "# code to click on the search button\n",
    "search_btn = driver.find_element_by_xpath('//button[@class=\"L0Z3Pu\"]')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2ee153b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = driver.find_elements_by_xpath('//nav[@class=\"yFHi8N\"]//a')\n",
    "\n",
    "# extract all the product search links from the above search result\n",
    "prod_urls=[]\n",
    "for i in url[:5]:\n",
    "    prod_urls.append(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9fbd6efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths of columns: 200 164 200 200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sneaker Brand</th>\n",
       "      <th>Sneaker Description</th>\n",
       "      <th>Sneaker Price</th>\n",
       "      <th>Sneaker Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>luxury fashion</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹379</td>\n",
       "      <td>57% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Echor</td>\n",
       "      <td>Men's Sneakers Walking Shoes - Lightweight Cla...</td>\n",
       "      <td>₹429</td>\n",
       "      <td>59% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Magnolia</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹356</td>\n",
       "      <td>64% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Combo Pack Of 4 Casual Shoes Loafer Shoes Snea...</td>\n",
       "      <td>₹474</td>\n",
       "      <td>86% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Longwalk</td>\n",
       "      <td>Men Boxer Sneakers For Men</td>\n",
       "      <td>₹236</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>DUCATI</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹379</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹359</td>\n",
       "      <td>28% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>LuvShus</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹449</td>\n",
       "      <td>55% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>SHOEFLY</td>\n",
       "      <td>Smash Vulc Sneakers For Men</td>\n",
       "      <td>₹362</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>luxury fashion</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "      <td>87% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sneaker Brand                                Sneaker Description  \\\n",
       "0   luxury fashion                                   Sneakers For Men   \n",
       "1            Echor  Men's Sneakers Walking Shoes - Lightweight Cla...   \n",
       "2         Magnolia                                   Sneakers For Men   \n",
       "3           BRUTON  Combo Pack Of 4 Casual Shoes Loafer Shoes Snea...   \n",
       "4         Longwalk                         Men Boxer Sneakers For Men   \n",
       "..             ...                                                ...   \n",
       "95          DUCATI                                   Sneakers For Men   \n",
       "96           BIRDE                                   Sneakers For Men   \n",
       "97         LuvShus                                   Sneakers For Men   \n",
       "98         SHOEFLY                        Smash Vulc Sneakers For Men   \n",
       "99  luxury fashion                                   Sneakers For Men   \n",
       "\n",
       "   Sneaker Price Sneaker Discount  \n",
       "0           ₹379          57% off  \n",
       "1           ₹429          59% off  \n",
       "2           ₹356          64% off  \n",
       "3           ₹474          86% off  \n",
       "4           ₹236          52% off  \n",
       "..           ...              ...  \n",
       "95          ₹379          80% off  \n",
       "96          ₹359          28% off  \n",
       "97          ₹449          55% off  \n",
       "98          ₹362          70% off  \n",
       "99          ₹399          87% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code to extract brand details\n",
    "brand = []\n",
    "for i in prod_urls:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        prod_brand = driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "        for j in prod_brand:\n",
    "            brand.append(j.text)\n",
    "    except:\n",
    "        brand.append(\"---\")\n",
    "\n",
    "# code to extract product description\n",
    "descriptn = []\n",
    "for i in prod_urls:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        prod_descriptn = driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "        for j in prod_descriptn:\n",
    "            descriptn.append(j.text)\n",
    "    except:\n",
    "        descriptn.append(\"---\")\n",
    "\n",
    "# code to extract price of the product\n",
    "price = []\n",
    "for i in prod_urls:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        prod_price = driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "        for j in prod_price:\n",
    "            price.append(j.text)\n",
    "    except:\n",
    "        price.append(\"---\")\n",
    "\n",
    "# code to extract the discount percentage\n",
    "discount = []\n",
    "for i in prod_urls:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        prod_discount = driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]//span')\n",
    "        for j in prod_discount:\n",
    "            discount.append(j.text)\n",
    "    except:\n",
    "        discount.append(\"---\")\n",
    "\n",
    "# checking the length to get the data frame\n",
    "print(\"Lengths of columns:\", len(brand), len(descriptn), len(price), len(discount))\n",
    "\n",
    "# creating the data frame now\n",
    "df = pd.DataFrame({})\n",
    "df['Sneaker Brand']=brand[:100]\n",
    "df['Sneaker Description']=descriptn[:100]\n",
    "df['Sneaker Price']=price[:100]\n",
    "df['Sneaker Discount']=discount[:100]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b861db4",
   "metadata": {},
   "source": [
    "Question 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5d0e00a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the myntra shoes site url on the web driver\n",
    "url = \"https://www.myntra.com/shoes\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "95e413b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to click on the color filter for \"Black\"\n",
    "color_filter = driver.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label/div')\n",
    "color_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "400f0d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to click on the price filter for \"Rs. 6935 to Rs. 13621\" as “Rs. 6649 to Rs. 13099” is not available\n",
    "price_filter = driver.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label/div')\n",
    "price_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "05ba2dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Short-description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men BlackTraining or Gym Shoes</td>\n",
       "      <td>Rs. 6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Cell Fraction Fade Running</td>\n",
       "      <td>Rs. 6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>Men Solid Leather Formal Slip-Ons</td>\n",
       "      <td>Rs. 8099Rs. 8999(10% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>Men Solid Leather Formal Slip-Ons</td>\n",
       "      <td>Rs. 8999Rs. 9999(10% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Mesh Hybrid Fuego Running</td>\n",
       "      <td>Rs. 6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Heel &amp; Buckle London</td>\n",
       "      <td>Unisex Colourblocked Sneakers</td>\n",
       "      <td>Rs. 7192Rs. 8990(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Ruosh</td>\n",
       "      <td>Mercedes F1 Drift Cat Shoes</td>\n",
       "      <td>Rs. 8990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>PUMA Motorsport</td>\n",
       "      <td>Men Sneakers</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Leather Block Sandals</td>\n",
       "      <td>Rs. 6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Leather Formal Loafers</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Brand                  Short-description  \\\n",
       "0                   Puma     Men BlackTraining or Gym Shoes   \n",
       "1                   Puma     Men Cell Fraction Fade Running   \n",
       "2           Hush Puppies  Men Solid Leather Formal Slip-Ons   \n",
       "3           Hush Puppies  Men Solid Leather Formal Slip-Ons   \n",
       "4                   Puma          Mesh Hybrid Fuego Running   \n",
       "..                   ...                                ...   \n",
       "95  Heel & Buckle London      Unisex Colourblocked Sneakers   \n",
       "96                 Ruosh        Mercedes F1 Drift Cat Shoes   \n",
       "97       PUMA Motorsport                       Men Sneakers   \n",
       "98                  Puma              Leather Block Sandals   \n",
       "99                  Puma         Men Leather Formal Loafers   \n",
       "\n",
       "                        Price  \n",
       "0                    Rs. 6999  \n",
       "1                    Rs. 6999  \n",
       "2   Rs. 8099Rs. 8999(10% OFF)  \n",
       "3   Rs. 8999Rs. 9999(10% OFF)  \n",
       "4                    Rs. 6999  \n",
       "..                        ...  \n",
       "95  Rs. 7192Rs. 8990(20% OFF)  \n",
       "96                   Rs. 8990  \n",
       "97                   Rs. 7999  \n",
       "98                   Rs. 6999  \n",
       "99                   Rs. 8999  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating empty lists\n",
    "shoe_names=[]\n",
    "s_desc=[]\n",
    "short_desc=[]\n",
    "price=[]\n",
    "page_urls = []\n",
    "\n",
    "\n",
    "# scrape next pages urls\n",
    "nxt_page = driver.find_elements_by_xpath(\"//ul[@class='pagination-container']/li/a\")\n",
    "for i in nxt_page:\n",
    "    page_urls.append(i.get_attribute('href'))\n",
    "    \n",
    "#for scrapping shoe brand names\n",
    "for url in page_urls[:3]:\n",
    "    driver.get(url)\n",
    "    Names=driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']/h3\")  \n",
    "    for i in Names:\n",
    "        shoe_names.append(i.text)\n",
    "#for scrapping shoe short-description    \n",
    "    desc=driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']/h4\") \n",
    "    for i in desc:\n",
    "        s_desc.append(i.text)\n",
    "#The s_desc list contain blank description in every alternate index, so removing the blank or null description\n",
    "    for j in range(0,len(s_desc),2):\n",
    "        short_desc.append(s_desc[j])\n",
    "    \n",
    "    rs=driver.find_elements_by_xpath(\"//div[@class='product-price']\")  #for scrapping shoe prices\n",
    "    for i in rs:\n",
    "        price.append(i.text)    \n",
    "        \n",
    "df=pd.DataFrame({'Brand': shoe_names[:100],'Short-description': short_desc[:100],'Price': price[:100]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e3ad06",
   "metadata": {},
   "source": [
    "Question 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "966eefad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the amazon shopping site url on the web driver\n",
    "url = \"https://www.amazon.in/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fa3a2eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to write laptop in the search box\n",
    "search_prod = driver.find_element_by_xpath('//input[@id=\"twotabsearchtextbox\"]')\n",
    "search_prod.send_keys(\"Laptop\")\n",
    "\n",
    "# code to click on the search button\n",
    "search_btn = driver.find_element_by_xpath('//input[@id=\"nav-search-submit-button\"]')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3769ac1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HP 14 11th Gen Intel Core i5 Processor 14-inch...</td>\n",
       "      <td>62,990</td>\n",
       "      <td>4.2 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dell Vostro 3400 14\" (35.56 cms) FHD Anti Glar...</td>\n",
       "      <td>64,990</td>\n",
       "      <td>3.5 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenovo IdeaPad Slim 3 AMD Athlon Silver 3050U ...</td>\n",
       "      <td>79,990</td>\n",
       "      <td>3.4 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HP 15 AMD Athlon 15.6\" (39.62cms) HD Laptop (S...</td>\n",
       "      <td>58,980</td>\n",
       "      <td>3.5 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP Chromebook 14-inch (35.56 cms) Thin &amp; Light...</td>\n",
       "      <td>52,858</td>\n",
       "      <td>3.9 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HP 15 (2021) Thin &amp; Light Ryzen 3-3250 Laptop,...</td>\n",
       "      <td>29,990</td>\n",
       "      <td>3.8 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lenovo IdeaPad Slim 3 AMD 3020e 15.6\" (39.63cm...</td>\n",
       "      <td>28,420</td>\n",
       "      <td>3.6 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HP 15 Intel Pentium Gold 6405U Processor Entry...</td>\n",
       "      <td>27,990</td>\n",
       "      <td>3.4 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RDP ThinBook 1010 - Intel Celeron Quad Core Pr...</td>\n",
       "      <td>38,499</td>\n",
       "      <td>3.5 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AVITA Essential Refresh NE14A2INC43A-MB 14-inc...</td>\n",
       "      <td>30,049</td>\n",
       "      <td>4 out of 5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title   Price       Ratings\n",
       "0  HP 14 11th Gen Intel Core i5 Processor 14-inch...  62,990  4.2 out of 5\n",
       "1  Dell Vostro 3400 14\" (35.56 cms) FHD Anti Glar...  64,990  3.5 out of 5\n",
       "2  Lenovo IdeaPad Slim 3 AMD Athlon Silver 3050U ...  79,990  3.4 out of 5\n",
       "3  HP 15 AMD Athlon 15.6\" (39.62cms) HD Laptop (S...  58,980  3.5 out of 5\n",
       "4  HP Chromebook 14-inch (35.56 cms) Thin & Light...  52,858  3.9 out of 5\n",
       "5  HP 15 (2021) Thin & Light Ryzen 3-3250 Laptop,...  29,990  3.8 out of 5\n",
       "6  Lenovo IdeaPad Slim 3 AMD 3020e 15.6\" (39.63cm...  28,420  3.6 out of 5\n",
       "7  HP 15 Intel Pentium Gold 6405U Processor Entry...  27,990  3.4 out of 5\n",
       "8  RDP ThinBook 1010 - Intel Celeron Quad Core Pr...  38,499  3.5 out of 5\n",
       "9  AVITA Essential Refresh NE14A2INC43A-MB 14-inc...  30,049    4 out of 5"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating the empty list\n",
    "Title=[]\n",
    "Ratings=[]\n",
    "price=[]\n",
    "\n",
    "#locating the core i7 filter\n",
    "filter_button=driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item']/span\")\n",
    "for i in filter_button:\n",
    "    if i.text=='Intel Core i7':\n",
    "        i.click()\n",
    "        break\n",
    "        \n",
    "        \n",
    "#Scrapping Titles\n",
    "titles=driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "for i in titles[:10]:\n",
    "    Title.append(i.text)\n",
    "    \n",
    "    \n",
    "#scrapping Price\n",
    "prices=driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\")\n",
    "for i in prices[:10]:\n",
    "    price.append(i.text)\n",
    "\n",
    "urls=driver.find_elements_by_xpath(\"//a[@class='a-link-normal a-text-normal']\")#collecting urls of all the laptop\n",
    "UR=[]\n",
    "for i in urls[:10]:\n",
    "    UR.append(i.get_attribute('href'))#getting the url of first 10 laptops\n",
    "for url in UR:#loop for every laptop in the list\n",
    "    driver.get(url)\n",
    "    try:                                                                 \n",
    "        rating=driver.find_element_by_xpath(\"//span[@class='a-size-base a-nowrap']//span\")\n",
    "        Ratings.append(rating.text)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        Ratings.append(\"NO rating\")\n",
    "        \n",
    "#creating a dataframe\n",
    "df=pd.DataFrame({'Title':Title,\n",
    "                'Price':price,\n",
    "                'Ratings':Ratings})\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
